import casadi as ca
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Define the dynamics of the system
def plant_dynamics(x, u):
    dt = 0.01  # time step
    l1 = 1  # length of first link
    l2 = 1  # length of second link
    m1 = 1  # mass of first link
    m2 = 1  # mass of second link
    g = 9.81  # gravity

    q1, q2, dq1, dq2 = x[0], x[1], x[2], x[3]
    u1, u2 = u[0], u[1]

    ddq1 = (l1**2 * l2 * m2 * dq1**2 * ca.sin(-2 * q2 + 2 * q1)
            + 2 * u2 * ca.cos(-q2 + q1) * l1
            + 2 * (g * ca.sin(-2 * q2 + q1) * l1 * m2 / 2
                    + ca.sin(-q2 + q1) * dq2**2 * l1 * l2 * m2
                    + g * l1 * (m1 + m2 / 2) * ca.sin(q1)
                    - u1) * l2
            ) / l1**2 / l2 / (m2 * ca.cos(-2 * q2 + 2 * q1) - 2 * m1 - m2)
    
    ddq2 = (-g * l1 * l2 * m2 * (m1 + m2) * ca.sin(-q2 + 2 * q1)
            - l1 * l2**2 * m2**2 * dq2**2 * ca.sin(-2 * q2 + 2 * q1)
            - 2 * dq1**2 * l1**2 * l2 * m2 * (m1 + m2) * ca.sin(-q2 + q1)
            + 2 * u1 * ca.cos(-q2 + q1) * l2 * m2
            + l1 * (m1 + m2) * (ca.sin(q2) * g * l2 * m2 - 2 * u2)
            ) / l2**2 / l1 / m2 / (m2 * ca.cos(-2 * q2 + 2 * q1) - 2 * m1 - m2)
    
    x_next = ca.vertcat(dq1, dq2, ddq1, ddq2)
    return x + dt * x_next

# Solve the OCP for a given initial state
def solve_ocp(x_init, N, Q, R):
    opti = ca.Opti()

    x = opti.variable(4, N+1)
    u = opti.variable(2, N)
    
    cost = 0
    for k in range(N):
        cost += ca.mtimes(x[:, k].T, ca.mtimes(Q, x[:, k])) + ca.mtimes(u[:, k].T, ca.mtimes(R, u[:, k]))
        x_next = plant_dynamics(x[:, k], u[:, k])
        opti.subject_to(x[:, k+1] == x_next)
    
    opti.minimize(cost)
    
    opti.subject_to(x[:, 0] == x_init)
    opti.subject_to(opti.bounded(-1.99, u, 1.99))  # Slightly relaxed control input constraints

    opts = {'ipopt.print_level': 0, 'print_time': 0, 'ipopt.sb': 'yes'}
    opti.solver('ipopt', opts)
    
    sol = opti.solve()
    
    return sol.value(cost)

# Generate data for training the neural network
def generate_ocp_samples(num_samples, N, Q, R):
    X = []
    Y = []
    for _ in range(num_samples):
        x0 = np.random.uniform(low=-1.5, high=1.5, size=(4,))  # Adjusted range for better coverage
        try:
            J_x0 = solve_ocp(x0, N, Q, R)
            X.append(x0)
            Y.append(J_x0)
        except RuntimeError:
            continue
    return np.array(X), np.array(Y)

# Train the neural network to predict the cost
def train_neural_network(X, Y):
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1],)),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(1)  # Output layer for cost prediction
    ])
    
    model.compile(optimizer='adam', loss='mean_squared_error')
    model.fit(X, Y, epochs=100, batch_size=32)
    
    return model

# MPC controller with learned terminal cost
def mpc_controller(x_init, dt, N, Q, R, horizon_length, terminal_cost_model):
    x_current = x_init
    total_cost = 0
    
    x_traj = [x_init]
    u_traj = []

    for _ in range(horizon_length):
        # Solve OCP for current state
        opti = ca.Opti()
        x = opti.variable(4, N+1)
        u = opti.variable(2, N)

        cost = 0
        for k in range(N):
            cost += ca.mtimes(x[:, k].T, ca.mtimes(Q, x[:, k])) + ca.mtimes(u[:, k].T, ca.mtimes(R, u[:, k]))
            x_next = plant_dynamics(x[:, k], u[:, k])
            opti.subject_to(x[:, k+1] == x_next)
        
        terminal_cost = terminal_cost_model.predict(np.array([sol.value(x[:, -1])]))[0, 0]
        cost += terminal_cost
        opti.minimize(cost)
        
        opti.subject_to(x[:, 0] == x_current)
        opti.subject_to(opti.bounded(-1.99, u, 1.99))  # Slightly relaxed control input constraints

        opts = {'ipopt.print_level': 0, 'print_time': 0, 'ipopt.sb': 'yes'}
        opti.solver('ipopt', opts)
        
        sol = opti.solve()
        
        # Extract the first control action
        u_opt = sol.value(u[:, 0])
        x_opt = sol.value(x[:, 1])
        
        # Apply the first control action and update the state
        x_current = x_opt
        total_cost += sol.value(cost)  # Accumulate the total cost over the horizon
        
        x_traj.append(x_current)
        u_traj.append(u_opt)
    
    return np.array(x_traj), np.array(u_traj), total_cost

if __name__ == "__main__":
    dt = 0.01
    N = 10  # Horizon length for MPC
    horizon_length = 20  # Total steps in the MPC simulation
    Q = np.diag([10, 10, 10, 10])
    R = np.diag([1, 1])
    num_samples = 1000  # Number of OCPs to solve to generate training data

    # Generate and save OCP samples
    X, Y = generate_ocp_samples(num_samples, N, Q, R)

    # Check if we have enough data before training
    if X.shape[0] > 0:
        # Train the neural network
        model = train_neural_network(X, Y)

        # Test the MPC with the learned terminal cost
        x_init = np.random.uniform(low=-1.5, high=1.5, size=(4,))  # Match range with training data
        x_traj, u_traj, total_cost = mpc_controller(x_init, dt, N, Q, R, horizon_length, model)

        # Plotting the control inputs and state trajectories
        time_steps = np.arange(horizon_length + 1) * dt

        plt.figure()
        plt.plot(time_steps, x_traj[:, 0], label='$q_1$')
        plt.plot(time_steps, x_traj[:, 1], label='$q_2$')
        plt.legend()
        plt.title('State Trajectories')
        plt.xlabel('Time (s)')
        plt.ylabel('States')
        plt.show()

        plt.figure()
        plt.plot(time_steps[:-1], u_traj[:, 0], label='$u_1$')
        plt.plot(time_steps[:-1], u_traj[:, 1], label='$u_2$')
        plt.legend()
        plt.title('Control Inputs')
        plt.xlabel('Time (s)')
        plt.ylabel('Control Inputs')
        plt.show()

        print(f"Total running cost: {total_cost}")
    else:
        print("No valid samples generated. Please check OCP parameters or increase num_samples.")
